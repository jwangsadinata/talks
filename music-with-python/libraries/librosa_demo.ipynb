{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Librosa Demo\n",
    "\n",
    "In this demo, I hope to show you guys some of the things that you can do with the `librosa` library.\n",
    "\n",
    "We will explore the following:\n",
    " - How we can get information about the beat events from an audio clip\n",
    " - How to convert beat events into time stamps\n",
    " - How to obtain the chromagram and apply some enhancements to it\n",
    "\n",
    "A canonical example can be found at [http://librosa.github.io/librosa/](http://librosa.github.io/librosa/).\n",
    "\n",
    "Credits to Brian McFee for the code on chromagram enhancements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import librosa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can set the name of the file of our audio example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"titlescreen.wav\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the audio as waveform `y`, and store the sampling rate as `sr`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y, sr = librosa.load(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's run the default beat tracker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tempo, beat_frames = librosa.beat.beat_track(y=y, sr=sr)\n",
    "print('Estimated tempo: {:.2f} beats per minute'.format(tempo))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can convert the frame indices of beat events into timestamps, and output it into a csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beat_times = librosa.frames_to_time(beat_frames, sr=sr)\n",
    "librosa.output.times_csv('beat_times.csv', beat_times)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the next demo, we need to import a little bit more stuff."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import librosa.display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's get the chroma feature, using the constant-Q transformation (CQT)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chroma_orig = librosa.feature.chroma_cqt(y=y, sr=sr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this demo, let's zoom in on a 20-second chunk from the middle of the song."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = [slice(None), slice(*list(librosa.time_to_frames([0, 20])))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And for comparison, we'll show the CQT matrix as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = np.abs(librosa.cqt(y=y, sr=sr, bins_per_octave=12*3, n_bins=7*12*3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can plot the original chroma."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(2, 1, 1)\n",
    "librosa.display.specshow(librosa.amplitude_to_db(C, ref=np.max)[idx],\n",
    "                         y_axis='cqt_note', bins_per_octave=12*3)\n",
    "plt.colorbar()\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "librosa.display.specshow(chroma_orig[idx], y_axis='chroma')\n",
    "plt.colorbar()\n",
    "plt.ylabel('Original')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To further improve our feature chroma, we can try over-sampling the frequency axis to reduce sensitivity to tuning deviations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chroma_os = librosa.feature.chroma_cqt(y=y, sr=sr, bins_per_octave=12*3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot it again, to see the difference between our original chroma, and the new chroma that we have oversampled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(2, 1, 1)\n",
    "librosa.display.specshow(chroma_orig[idx], y_axis='chroma')\n",
    "plt.colorbar()\n",
    "plt.ylabel('Original')\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "librosa.display.specshow(chroma_os[idx], y_axis='chroma', x_axis='time')\n",
    "plt.colorbar()\n",
    "plt.ylabel('3x-over')\n",
    "plt.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
